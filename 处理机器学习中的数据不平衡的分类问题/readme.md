
## 处理机器学习中的不平衡分类问题

在信用卡诈骗案例中，我们将诈骗信息和正常交易信息进行可视化显示，我们可以发现正常交易的交易数远远大于诈骗交易的交易数。这样就会影响模型的输出。

### 为什么类别不平衡会影响模型的输出：

许多模型的输出类别是基于阈值的，例如逻辑回归中小于0.5的为反例，大于则为正例。在数据不平衡时，默认的阈值会导致模型输出倾向与类别数据多的类别，体现在模型整体的准确率很高。

对于极不均衡的分类问题，比如仅有1%的人是诈骗交易，99%的人是正常交易，最简单的分类模型就是将所有交易都划分为正常交易，模型都能得到99%的准确率，显然这样的模型并没有提供任何的信息。

在类别不平衡的情况下，对模型使用F值或者AUC值是更好的选择。

处理不平衡数据，可以从两方面考虑：一是改变数据分布，从数据层面使得类别更为平衡；

二是改变分类算法，在传统分类算法的基础上对不同类别采取不同的加权方式，使得模型更看重少数类。

本部分对数据层面的一些方法做一个介绍，改变数据分布的方法主要是以下几种重采样：

1）过采样：增加少数类样本的数量
2）欠采样：减少多数类样本的数量
3）综合采样：将过采样和欠采样结合

### 这里我们先提出两种解决方案也是数据分析中最常用的两种方法，下采样和过采样！

### 随机欠采样（下采样）的目标是通过随机地消除占多数的类的样本来平衡类分布；直到多数类和少数类的实例实现平衡，目标才算达成。

__下采样的优点：__
    
    它可以提升运行时间；并且当训练数据集很大时，可以通过减少样本数量来解决存储问题。

__下采样的缺点：__
    
    它会丢弃对构建规则分类器很重要的有价值的潜在信息。

    被随机欠采样选取的样本可能具有偏差。它不能准确代表大多数。从而在实际的测试数据集上得到不精确的结果。

### 随机过采样（Over-Sampling）通过随机复制少数类来增加其中的实例数量，从而可增加样本中少数类的代表性。

__过采样的优点：__

    与欠采样不同，这种方法不会带来信息损失。

    表现优于欠采样。

__过采样的缺点：__
    
    由于复制少数类事件，它加大了过拟合的可能性。


### 信息性过采样：合成少数类过采样技术（SMOTE）:



### 改进的合成少数类过采样技术（MSMOTE）


## 算法集成技术

上述部分涉及通过重采样原始数据提供平衡类来处理不平衡数据，在本节中，我们将研究一种替代方法：修改现有的分类算法，使其适用于不平衡数据集。

集成方法的主要目的是提高单个分类器的性能。该方法从原始数据中构建几个两级分类器，然后整合它们的预测。

###  基于 Bagging 的方法

### 基于 Boosting 的方法

### 自适应 boosting——AdaBoost

### 梯度树 boosting

### XGBoost



