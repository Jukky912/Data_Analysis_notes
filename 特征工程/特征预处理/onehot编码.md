### Onehot编码：

几乎所有特征都可以分为两个类别： __连续型特征和离散型特征。__

数据处理时会用到以下的知识：

__连续性特征使用归一化。__

    特征A的取值范围是[-1000,1000]，特征B的取值范围是[-1,1]。
    如果使用logistic回归，w1x1+w2x2，因为x1的取值太大了，所以x2基本起不了作用。
    所以，必须进行特征的归一化，每个特征都单独进行归一化。

__离散型使用独热编码（哑变量）。__


首先我们根据最左侧的表格对比我们的Binary和我们的One-hot

Binarys 根据我们的二进制进行一个表示的 000 表示0  ，001表示1，010表示2 ……  这种编码方式的好处在于，我们可以尽可能的对我们的编码方式进行一个压缩，同样的一个信息我们使用我们这种编码方式可能占用的位数尽量的少。
 
One-hot的编码方式：我们可以假设我们的One-hot是一个字典，这里面的数字只有一个数字是1，是1的这个数组相当于我们的标签中的索引，00000001 表示0 00000010 表示1 即第几个数字为1，那表示的就是它对应的位置减一。

One-hot的其中一个应用就是字典：
比如我们现在有 单词 man woman boy girl等存在字典中，这些单词单独存在是难以创建索引的，一种方式就是我们的one-hot编码，比如我们这里有9个单词，我们现在创建一个长度为9的向量做one-hot编码表示，每一个单词都可以得到一个1*9这样的向量表达，这个时候我们只要读取到我们的one-hot编码中哪一个状态位为1，那么他就表示哪一个单词。(上面的1-9就是我们的key 左边的单词就是我们的value)

这样有什么好处呢，好处是可以和我们的softmax的概率进行一个结合 这个后面再展开

在MINIST数据集中我们使用one-hot可以帮助我们进行损失值的计算，实际上我们在训练神经网络语言模型时，我们也需要对语言词汇表进行一个表示，此时我们使用one-hot词汇表就不太适用，加入现在我们的词汇表中有6000个单词，那我们就需要存储6000个向量，这往往是没有必要的。因为我们的单词之间可能是有关系的，使用one-hot则表示我们的单词和单词之间完全没有关系，都是独立的。在这里使用one-hot是因为它刚好适应我们的运用场景，我们的10个数字都是独立存在不相关的。




