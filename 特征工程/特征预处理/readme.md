#  数据的预处理

通过特征提取，我们能得到未经处理的特征，这时的特征可能有以下问题：

__1、不属于同一量纲：__ 即特征的规格不一样，不能够放在一起比较。无量纲化可以解决这一问题。

__2、信息冗余：__ 对于某些定量特征，其包含的有效信息为区间划分，例如学习成绩，假若只关心“及格”或不“及格”，那么需要将定量的考分，转换成“1”和“0”表示及格和未及格。二值化可以解决这一问题。

__3、定性特征不能直接使用：__ 某些机器学习算法和模型只能接受定量特征的输入，那么需要将定性特征转换为定量特征。最简单的方式是为每一种定性值指定一个定量值，但是这种方式过于灵活，增加了调参的工作。通常使用哑编码的方式将定性特征转换为定量特征：假设有N种定性值，则将这一个特征扩展为N种特征，当原始特征值为第i种定性值时，第i个扩展特征赋值为1，其他扩展特征赋值为0。哑编码的方式相比直接指定的方式，不用增加调参的工作，对于线性模型来说，使用哑编码后的特征可达到非线性的效果。

__4、存在缺失值：__ 缺失值需要补充。

__5、信息利用率低：__ 不同的机器学习算法和模型对数据中信息的利用是不同的，之前提到在线性模型中，使用对定性特征哑编码可以达到非线性的效果。类似地，对定量变量多项式化，或者进行其他的转换，都能达到非线性的效果。

我们 __使用sklearn中的preproccessing库__ 来进行数据预处理，可以覆盖以上问题的解决方案。

## 一、无量钢化 

无量纲化使不同规格的数据转换到同一规格。常见的无量纲化方法有标准化和区间缩放法。标准化的前提是特征值服从正态分布，标准化后，其转换成标准正态分布。区间缩放法利用了边界值信息，将特征的取值区间缩放到某个特点的范围，例如[0, 1]等。

### 标准化

__1.1、z-score标准化：__ 

默认情况下，推荐使用zscore标准化。(主要原因是max-min标准化有一个问题，就是如果测试集里的数据特征的值出现比训练集的特征值最大值还大，或者比训练集的特征值最小值还小的情况，需要特殊处理。)

          
这是最常见的特征预处理方式，基本所有的线性模型在拟合的时候都会做 z-score标准化。具体的方法是求出样本特征x的均值mean和标准差std，然后用（x-mean)/std来代替原特征。这样特征就变成了均值为0，方差为1了 __(标准正态分布)__。 

在sklearn中，我们 __可以用StandardScaler来做z-score标准化__ 。当然，如果我们是用pandas做数据预处理，可以自己在数据框里面减去均值，再除以方差，自己做z-score标准化。    

__如：当只有一个特征时，我们进行标准化也要用双 [],即[[]]__

      ss=StandardScaler()
      train_x=data[['False']]
      train_x=ss.fit_transform(train_x)


__1.2、max-min区间缩放法：__ 

也称为离差标准化，预处理后使特征值映射到[0,1]之间。具体的方法是求出样本特征x的最大值max和最小值min，然后用(x-min)/(max-min)来代替原特征。如果我们希望将数据映射到任意一个区间[a,b]，而不是[0,1]，那么也很简单。用(x-min)(b-a)/(max-min)+a来代替原特征即可。

在sklearn中，我们可以用MinMaxScaler来做max-min标准化。 __这种方法的问题就是如果测试集或者预测数据里的特征有小于min，或者大于max的数据，会导致max和min发生变化，需要重新计算。__

__所以实际算法中， 除非你对特征的取值区间有需求，否则max-min标准化没有 z-score标准化好用。__


### 归一化

__1.3、Normalizer归一化：__

归一化依照特征矩阵的行处理数据，其目的在于样本向量在点乘运算或其他核函数计算相似性时，拥有统一的标准，也就是说都转化为“单位向量”。 


### 标准化和归一化的异同

#### 归一化方法：

      1、把数变为（0，1）之间的小数
      主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。

      2、把有量纲表达式变为无量纲表达式
      归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。


#### 归一化带来的好处

      1.提升模型的收敛速度
      2.提升模型的精度  
      3.深度学习中数据归一化可以防止模型梯度爆炸。


#### 标准化方法：

      1、标准化是通过特征的平均值和标准差，将特征缩放成一个标准的正态分布，缩放后均值为0，方差为1。但即使数据不服从正态分布，也可以用此法。
      特别适用于数据的最大值和最小值未知，或存在孤立点。

      2、标准化是为了方便数据的下一步处理，而进行的数据缩放等变换，不同于归一化，并不是为了方便与其他数据一同处理或比较。



### 关于标准化后应该注意    <------- 重点

__如果训练模型时需要对特征进行标准化，那么测试的时候你需要使用训练集的标准化对应参数进行标准化。__

__比如：__ 

训练集某特征的均值是3， 标准差是4， 你做了z-score标准化，变成了均值0， 标准差1的数据，最后训练了模型。对于你的测试集的该特征，你需要减3再除以4，这样标准化后再去做预测。
      
      

         
### Sklearn的数据预处理模块：


      类                  功能                                   说明
    StandardScaler      无量纲化              标准化，基于特征矩阵的列，将特征值转换至服从标准正态分布

    MinMaxScaler        无量纲化              区间缩放，基于最大最小值，将特征值转换到[0, 1]区间上

    Normalizer          归一化                基于特征矩阵的行，将样本向量转换为“单位向量”

    Binarizer           二值化                基于给定阈值，将定量特征按阈值划分

    OneHotEncoder       哑编码                将定性数据编码为定量数据

    Imputer             缺失值计算             计算缺失值，缺失值可填充为均值等

    PolynomialFeatures  多项式数据转换         多项式数据转换

    FunctionTransformer 自定义单元数据转换      使用单变元的函数来转换数据函数来转换数据


## 注意

__是否进行标准化，可能会影响模型的预测分数,模型的分数可能会偏高也可能会偏低__


