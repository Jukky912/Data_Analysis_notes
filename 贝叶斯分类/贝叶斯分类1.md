# 贝叶斯分类


## 朴素贝叶斯分类器的三个流程：
  
  __准备阶段：__
                 
  在这个阶段我们需要确定特征属性，比如对于通过“身高”为高、“体重”为中等、“鞋码”为中等，这些特征 __预测性别__ 问题中，对每个特征属性进行适当划分，然后由人工对一部分数据进行分类，形成训练样本。
  
  __训练阶段:__
             
  这个阶段就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率。输入是特征属性和训练样本，输出是分类器。
    
  __应用阶段:__
               
  这个阶段是使用分类器对新数据进行分类。输入是分类器和新数据，输出是新数据的分类结果。

## 贝叶斯原理概念：
  
  __一、先验概率：__
             
   __通过经验来判断事情发生的概率__ ，比如说“贝叶死”的发病率是万分之一，就是先验概率。再比如南方的梅雨季是 6-7 月，就是通过往年的气候总结出来的经验，这个时候下雨的概率就比其他时间高出很多。
    
  __二、后验概率：__
          
   __后验概率就是发生结果之后，推测原因的概率。__ 比如说某人查出来了患有“贝叶死”，那么患病的原因可能是 A、B 或 C。患有“贝叶死”是因为原因 A 的概率就是后验概率。它是属于条件概率的一种。
    
  __三、条件概率:__
            
   __事件 A 在另外一个事件 B 已经发生条件下的发生概率，__ 表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。比如原因 A 的条件下，患有“贝叶死”的概率，就是条件概率。
    
    
    

## 对于离散值的分类，对于连续值的分类

  对于离散值我们直接进行概率计算，对于连续的值我们需要将其看成正态分布，然后计算均值和标准差，通过均值和标准差来求解概率。


## Sklearn提供了3个朴素贝叶斯算法：
  
  __高斯朴素贝叶斯：__ 特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。
  __多项式朴素贝叶斯：__ 特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。
  __伯努利朴素贝叶斯：__ 特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。

## TF-IDF值：

  __词频 TF__ 计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。
    
      计算公式：词频 TF=单词出现的次数/该文档的总单词数
       
  __逆向文档频率 IDF__ ，是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。
     
      计算公式：逆向文档频率 IDF=log(文档总数/该单词出现的文档数+1)
     
__TF-IDF 实际上是词频 TF 和逆向文档频率 IDF 的乘积__ 。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。

  __例子__
      
  假设一个文件夹里一共有 10 篇文档，其中一篇文档有 1000 个单词，“this”这个单词出现 20 次，“bayes”出现了 5 次。“this”在所有文档中均出现过，而“bayes”只在 2 篇文档中出现过。我们来计算一下这两个词语的 TF-IDF 值。
  
  __针对“this”，计算 TF-IDF 值：__
      
      词频 TF =20/100=0.02
      逆向文档频率 IDF = log(10/10+1)=-0.0414
      
      TF-IDF=0.02*(-0.0414)=-8.28e-4。
  
  __针对“bayes”，计算 TF-IDF 值：__
  
      词频 TF =5/1000=0.005
      逆向文档频率 IDF = log(10/2+1)=0.5229
      
      TF-IDF=0.005 * 0.5229=2.61e-3。    
      
 ## 总结：  
  __“bayes”的 TF-IDF 值要大于“this”的 TF-IDF 值。这就说明用“bayes”这个单词做区分比单词“this”要好。__
     
     
## 案例：如何对文档进行分类：

__流程：__
            
  文档输入 --> 对文档进行分词 --> 加载停用词 --> 计算单词权重 (准备阶段) --> 生成分类器 --> 分类器做预测 --> 计算正确率  (分类阶段)
  
  
  
  
  
  
  

